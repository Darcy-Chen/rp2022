{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not open 'mbv1_1.0_12_90_68.4.tflite'.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m interpreter \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInterpreter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmbv1_1.0_12_90_68.4.tflite\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m interpreter\u001B[38;5;241m.\u001B[39mallocate_tensors()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SparseRT/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py:455\u001B[0m, in \u001B[0;36mInterpreter.__init__\u001B[0;34m(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors)\u001B[0m\n\u001B[1;32m    448\u001B[0m custom_op_registerers_by_name \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    449\u001B[0m     x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_custom_op_registerers \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mstr\u001B[39m)\n\u001B[1;32m    450\u001B[0m ]\n\u001B[1;32m    451\u001B[0m custom_op_registerers_by_func \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    452\u001B[0m     x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_custom_op_registerers \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mstr\u001B[39m)\n\u001B[1;32m    453\u001B[0m ]\n\u001B[1;32m    454\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpreter \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 455\u001B[0m     \u001B[43m_interpreter_wrapper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCreateWrapperFromFile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_resolver_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_op_registerers_by_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_op_registerers_by_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperimental_preserve_all_tensors\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpreter:\n\u001B[1;32m    459\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFailed to open \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(model_path))\n",
      "\u001B[0;31mValueError\u001B[0m: Could not open 'mbv1_1.0_12_90_68.4.tflite'."
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"mbv1_1.0_12_90_68.4.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_tensors_meta = []\n",
    "bias_tensors = []\n",
    "\n",
    "for j in range(len(stuff)):\n",
    "    if \"bias\" in stuff[j]['name']:\n",
    "        bias_tensors_meta.append(stuff[j])\n",
    "        bias_tensors.append(interpreter.get_tensor(j))\n",
    "        name = bias_tensors_meta[-1]['name'].split(\"/\")[1]\n",
    "        print(name, bias_tensors[-1].shape)\n",
    "        \n",
    "        np.save(name + \"_bias.npy\",bias_tensors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_tensors_meta = []\n",
    "weight_tensors = []\n",
    "\n",
    "for j in range(len(stuff)):\n",
    "    if \"weight\" in stuff[j]['name']:\n",
    "        weight_tensors_meta.append(stuff[j])\n",
    "        weight_tensors.append(interpreter.get_tensor(j))\n",
    "        name = weight_tensors_meta[-1]['name'].split(\"/\")[1]\n",
    "        print(name, weight_tensors[-1].shape)\n",
    "        if \"depthwise\" not in name:\n",
    "            np.save(name + \".npy\",weight_tensors[-1].squeeze().transpose())\n",
    "        else:\n",
    "            np.save(name + \".npy\",weight_tensors[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.Tensor(weight_tensors[1].squeeze().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = weight_tensors[2].squeeze().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a[np.argsort([len(i) for i in [np.where(a[j])[0] for j in range(512)]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(512):\n",
    "    print(np.where(a[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(a,cmap='seismic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthwise_filters = torch.Tensor(weight_tensors[13]).permute(3,0,1,2)\n",
    "groupwise_filters = torch.Tensor(weight_tensors[0]).permute(0,3,1,2)\n",
    "depthwise_bias = torch.Tensor(bias_tensors[13])\n",
    "groupwise_bias = torch.Tensor(bias_tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_tensors[13][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.Tensor(np.random.normal(size=(1,32,112,112)))\n",
    "\n",
    "intermediate = torch.nn.functional.conv2d(input_image, depthwise_filters, bias=depthwise_bias, stride=1, padding=1, dilation=1, groups=32)\n",
    "intermediate = torch.nn.functional.relu(intermediate)\n",
    "result_2 = torch.nn.functional.linear(torch.squeeze(intermediate).permute(1,2,0).contiguous().view(-1,32).unsqueeze(0),torch.squeeze(groupwise_filters),bias=None)\n",
    "result_1 = torch.nn.functional.conv2d(intermediate,groupwise_filters,bias=groupwise_bias,stride=1,padding=0,dilation=1,groups=1)\n",
    "result_2 = torch.nn.functional.relu(result_2)\n",
    "result_1 = torch.nn.functional.relu(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.sum(result_1) - torch.sum(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"input_image.npy\",input_image.squeeze().data.numpy())\n",
    "np.save(\"depthwise_filters.npy\",depthwise_filters.squeeze().data.numpy())\n",
    "np.save(\"result.npy\",np.transpose(result_2.squeeze().data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = result_2.squeeze().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.transpose(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[61,12543]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate.squeeze()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_in = torch.nn.functional.pad(input_image,(8,8,1,1))\n",
    "np.save(\"padded_input_image.npy\",padded_in.squeeze().data.numpy())\n",
    "padded_out = torch.nn.functional.pad(result_1,(8,8,1,1))\n",
    "np.save(\"padded_result.npy\",padded_out.squeeze().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor(np.random.normal(size=(1,3,224,224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = nn.MaxPool2d(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1(m(a)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}